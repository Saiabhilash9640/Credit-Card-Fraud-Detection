{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7173563,"sourceType":"datasetVersion","datasetId":4145023}],"dockerImageVersionId":30615,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:28:13.932883Z","iopub.execute_input":"2023-12-11T07:28:13.933281Z","iopub.status.idle":"2023-12-11T07:28:15.799055Z","shell.execute_reply.started":"2023-12-11T07:28:13.933251Z","shell.execute_reply":"2023-12-11T07:28:15.797749Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"raw","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:31:12.806619Z","iopub.execute_input":"2023-12-11T07:31:12.807038Z","iopub.status.idle":"2023-12-11T07:31:12.811774Z","shell.execute_reply.started":"2023-12-11T07:31:12.807006Z","shell.execute_reply":"2023-12-11T07:31:12.810579Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/creditcard/creditcard.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:28:15.801478Z","iopub.execute_input":"2023-12-11T07:28:15.802119Z","iopub.status.idle":"2023-12-11T07:28:20.580816Z","shell.execute_reply.started":"2023-12-11T07:28:15.802073Z","shell.execute_reply":"2023-12-11T07:28:20.579625Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62      0  \n1  0.125895 -0.008983  0.014724    2.69      0  \n2 -0.139097 -0.055353 -0.059752  378.66      0  \n3 -0.221929  0.062723  0.061458  123.50      0  \n4  0.502292  0.219422  0.215153   69.99      0  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:28:20.582037Z","iopub.execute_input":"2023-12-11T07:28:20.582338Z","iopub.status.idle":"2023-12-11T07:28:21.158667Z","shell.execute_reply.started":"2023-12-11T07:28:20.582310Z","shell.execute_reply":"2023-12-11T07:28:21.157729Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                Time            V1            V2            V3            V4  \\\ncount  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \nstd     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \nmin         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \nmax    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n\n                 V5            V6            V7            V8            V9  \\\ncount  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \nstd    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \nmin   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \nmax    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n\n       ...           V21           V22           V23           V24  \\\ncount  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \nstd    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \nmin    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \nmax    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n\n                V25           V26           V27           V28         Amount  \\\ncount  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \nmean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \nstd    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \nmin   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \nmax    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n\n               Class  \ncount  284807.000000  \nmean        0.001727  \nstd         0.041527  \nmin         0.000000  \n25%         0.000000  \n50%         0.000000  \n75%         0.000000  \nmax         1.000000  \n\n[8 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>284807.000000</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>...</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>284807.000000</td>\n      <td>284807.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>94813.859575</td>\n      <td>1.168375e-15</td>\n      <td>3.416908e-16</td>\n      <td>-1.379537e-15</td>\n      <td>2.074095e-15</td>\n      <td>9.604066e-16</td>\n      <td>1.487313e-15</td>\n      <td>-5.556467e-16</td>\n      <td>1.213481e-16</td>\n      <td>-2.406331e-15</td>\n      <td>...</td>\n      <td>1.654067e-16</td>\n      <td>-3.568593e-16</td>\n      <td>2.578648e-16</td>\n      <td>4.473266e-15</td>\n      <td>5.340915e-16</td>\n      <td>1.683437e-15</td>\n      <td>-3.660091e-16</td>\n      <td>-1.227390e-16</td>\n      <td>88.349619</td>\n      <td>0.001727</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>47488.145955</td>\n      <td>1.958696e+00</td>\n      <td>1.651309e+00</td>\n      <td>1.516255e+00</td>\n      <td>1.415869e+00</td>\n      <td>1.380247e+00</td>\n      <td>1.332271e+00</td>\n      <td>1.237094e+00</td>\n      <td>1.194353e+00</td>\n      <td>1.098632e+00</td>\n      <td>...</td>\n      <td>7.345240e-01</td>\n      <td>7.257016e-01</td>\n      <td>6.244603e-01</td>\n      <td>6.056471e-01</td>\n      <td>5.212781e-01</td>\n      <td>4.822270e-01</td>\n      <td>4.036325e-01</td>\n      <td>3.300833e-01</td>\n      <td>250.120109</td>\n      <td>0.041527</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-5.640751e+01</td>\n      <td>-7.271573e+01</td>\n      <td>-4.832559e+01</td>\n      <td>-5.683171e+00</td>\n      <td>-1.137433e+02</td>\n      <td>-2.616051e+01</td>\n      <td>-4.355724e+01</td>\n      <td>-7.321672e+01</td>\n      <td>-1.343407e+01</td>\n      <td>...</td>\n      <td>-3.483038e+01</td>\n      <td>-1.093314e+01</td>\n      <td>-4.480774e+01</td>\n      <td>-2.836627e+00</td>\n      <td>-1.029540e+01</td>\n      <td>-2.604551e+00</td>\n      <td>-2.256568e+01</td>\n      <td>-1.543008e+01</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>54201.500000</td>\n      <td>-9.203734e-01</td>\n      <td>-5.985499e-01</td>\n      <td>-8.903648e-01</td>\n      <td>-8.486401e-01</td>\n      <td>-6.915971e-01</td>\n      <td>-7.682956e-01</td>\n      <td>-5.540759e-01</td>\n      <td>-2.086297e-01</td>\n      <td>-6.430976e-01</td>\n      <td>...</td>\n      <td>-2.283949e-01</td>\n      <td>-5.423504e-01</td>\n      <td>-1.618463e-01</td>\n      <td>-3.545861e-01</td>\n      <td>-3.171451e-01</td>\n      <td>-3.269839e-01</td>\n      <td>-7.083953e-02</td>\n      <td>-5.295979e-02</td>\n      <td>5.600000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>84692.000000</td>\n      <td>1.810880e-02</td>\n      <td>6.548556e-02</td>\n      <td>1.798463e-01</td>\n      <td>-1.984653e-02</td>\n      <td>-5.433583e-02</td>\n      <td>-2.741871e-01</td>\n      <td>4.010308e-02</td>\n      <td>2.235804e-02</td>\n      <td>-5.142873e-02</td>\n      <td>...</td>\n      <td>-2.945017e-02</td>\n      <td>6.781943e-03</td>\n      <td>-1.119293e-02</td>\n      <td>4.097606e-02</td>\n      <td>1.659350e-02</td>\n      <td>-5.213911e-02</td>\n      <td>1.342146e-03</td>\n      <td>1.124383e-02</td>\n      <td>22.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>139320.500000</td>\n      <td>1.315642e+00</td>\n      <td>8.037239e-01</td>\n      <td>1.027196e+00</td>\n      <td>7.433413e-01</td>\n      <td>6.119264e-01</td>\n      <td>3.985649e-01</td>\n      <td>5.704361e-01</td>\n      <td>3.273459e-01</td>\n      <td>5.971390e-01</td>\n      <td>...</td>\n      <td>1.863772e-01</td>\n      <td>5.285536e-01</td>\n      <td>1.476421e-01</td>\n      <td>4.395266e-01</td>\n      <td>3.507156e-01</td>\n      <td>2.409522e-01</td>\n      <td>9.104512e-02</td>\n      <td>7.827995e-02</td>\n      <td>77.165000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>172792.000000</td>\n      <td>2.454930e+00</td>\n      <td>2.205773e+01</td>\n      <td>9.382558e+00</td>\n      <td>1.687534e+01</td>\n      <td>3.480167e+01</td>\n      <td>7.330163e+01</td>\n      <td>1.205895e+02</td>\n      <td>2.000721e+01</td>\n      <td>1.559499e+01</td>\n      <td>...</td>\n      <td>2.720284e+01</td>\n      <td>1.050309e+01</td>\n      <td>2.252841e+01</td>\n      <td>4.584549e+00</td>\n      <td>7.519589e+00</td>\n      <td>3.517346e+00</td>\n      <td>3.161220e+01</td>\n      <td>3.384781e+01</td>\n      <td>25691.160000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:28:21.161146Z","iopub.execute_input":"2023-12-11T07:28:21.161537Z","iopub.status.idle":"2023-12-11T07:28:21.204096Z","shell.execute_reply.started":"2023-12-11T07:28:21.161508Z","shell.execute_reply":"2023-12-11T07:28:21.202889Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 284807 entries, 0 to 284806\nData columns (total 31 columns):\n #   Column  Non-Null Count   Dtype  \n---  ------  --------------   -----  \n 0   Time    284807 non-null  float64\n 1   V1      284807 non-null  float64\n 2   V2      284807 non-null  float64\n 3   V3      284807 non-null  float64\n 4   V4      284807 non-null  float64\n 5   V5      284807 non-null  float64\n 6   V6      284807 non-null  float64\n 7   V7      284807 non-null  float64\n 8   V8      284807 non-null  float64\n 9   V9      284807 non-null  float64\n 10  V10     284807 non-null  float64\n 11  V11     284807 non-null  float64\n 12  V12     284807 non-null  float64\n 13  V13     284807 non-null  float64\n 14  V14     284807 non-null  float64\n 15  V15     284807 non-null  float64\n 16  V16     284807 non-null  float64\n 17  V17     284807 non-null  float64\n 18  V18     284807 non-null  float64\n 19  V19     284807 non-null  float64\n 20  V20     284807 non-null  float64\n 21  V21     284807 non-null  float64\n 22  V22     284807 non-null  float64\n 23  V23     284807 non-null  float64\n 24  V24     284807 non-null  float64\n 25  V25     284807 non-null  float64\n 26  V26     284807 non-null  float64\n 27  V27     284807 non-null  float64\n 28  V28     284807 non-null  float64\n 29  Amount  284807 non-null  float64\n 30  Class   284807 non-null  int64  \ndtypes: float64(30), int64(1)\nmemory usage: 67.4 MB\n","output_type":"stream"}]},{"cell_type":"code","source":"df[df.Amount==0]","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:28:21.205632Z","iopub.execute_input":"2023-12-11T07:28:21.206042Z","iopub.status.idle":"2023-12-11T07:28:21.248611Z","shell.execute_reply.started":"2023-12-11T07:28:21.206008Z","shell.execute_reply":"2023-12-11T07:28:21.247519Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"            Time        V1        V2        V3        V4        V5        V6  \\\n383        282.0 -0.356466  0.725418  1.971749  0.831343  0.369681 -0.107776   \n514        380.0 -1.299837  0.881817  1.452842 -1.293698 -0.025105 -1.170103   \n534        403.0  1.237413  0.512365  0.687746  1.693872 -0.236323 -0.650232   \n541        406.0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n575        430.0 -1.860258 -0.629859  0.966570  0.844632  0.759983 -1.481173   \n...          ...       ...       ...       ...       ...       ...       ...   \n283719  171817.0 -0.750414  0.904175  0.996461  0.427284  1.720336  0.929256   \n283782  171870.0  2.083677 -0.065811 -1.442870  0.135416  0.043035 -1.306975   \n283949  172027.0  2.132569 -0.057836 -1.724522 -0.030326  0.412146 -0.903088   \n284085  172140.0 -2.210521 -1.039425  0.189704 -1.291932  3.742120 -1.665061   \n284770  172759.0 -0.822731  1.270140 -0.138566  0.479620  1.242101  0.795218   \n\n              V7        V8        V9  ...       V21       V22       V23  \\\n383     0.751610 -0.120166 -0.420675  ...  0.020804  0.424312 -0.015989   \n514     0.861610 -0.193934  0.592001  ... -0.272563 -0.360853  0.223911   \n534     0.118066 -0.230545 -0.808523  ... -0.077543 -0.178220  0.038722   \n541    -2.537387  1.391657 -2.770089  ...  0.517232 -0.035049 -0.465211   \n575    -0.509681  0.540722 -0.733623  ...  0.268028  0.125515 -0.225029   \n...          ...       ...       ...  ...       ...       ...       ...   \n283719  0.794272  0.176719 -1.836261  ...  0.050750  0.115532 -0.623995   \n283782  0.335835 -0.371635  0.730560  ... -0.147536 -0.246599  0.194758   \n283949  0.345843 -0.348132  0.722638  ... -0.188739 -0.343876  0.105024   \n284085  3.120388 -2.324089  0.364926  ... -0.286359  1.326003 -0.361764   \n284770  0.454284  0.556038 -1.550610  ...  0.138766  0.450908 -0.192146   \n\n             V24       V25       V26       V27       V28  Amount  Class  \n383     0.466754 -0.809962  0.657334 -0.043150 -0.046401     0.0      0  \n514     0.598930 -0.397705  0.637141  0.234872  0.021379     0.0      0  \n534     0.471218  0.289249  0.871803 -0.066884  0.012986     0.0      0  \n541     0.320198  0.044519  0.177840  0.261145 -0.143276     0.0      1  \n575     0.586664 -0.031598  0.570168 -0.043007 -0.223739     0.0      0  \n...          ...       ...       ...       ...       ...     ...    ...  \n283719 -0.186896  0.733759  2.558151 -0.188835  0.001654     0.0      0  \n283782 -0.082277  0.012887 -0.069278 -0.048995 -0.065482     0.0      0  \n283949 -0.763831  0.117381 -0.027682 -0.047514 -0.071700     0.0      0  \n284085 -0.268117  1.051309  0.334629 -1.930149 -0.899888     0.0      0  \n284770 -0.196218 -0.261664  2.372675 -0.042743  0.109613     0.0      0  \n\n[1825 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>383</th>\n      <td>282.0</td>\n      <td>-0.356466</td>\n      <td>0.725418</td>\n      <td>1.971749</td>\n      <td>0.831343</td>\n      <td>0.369681</td>\n      <td>-0.107776</td>\n      <td>0.751610</td>\n      <td>-0.120166</td>\n      <td>-0.420675</td>\n      <td>...</td>\n      <td>0.020804</td>\n      <td>0.424312</td>\n      <td>-0.015989</td>\n      <td>0.466754</td>\n      <td>-0.809962</td>\n      <td>0.657334</td>\n      <td>-0.043150</td>\n      <td>-0.046401</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>514</th>\n      <td>380.0</td>\n      <td>-1.299837</td>\n      <td>0.881817</td>\n      <td>1.452842</td>\n      <td>-1.293698</td>\n      <td>-0.025105</td>\n      <td>-1.170103</td>\n      <td>0.861610</td>\n      <td>-0.193934</td>\n      <td>0.592001</td>\n      <td>...</td>\n      <td>-0.272563</td>\n      <td>-0.360853</td>\n      <td>0.223911</td>\n      <td>0.598930</td>\n      <td>-0.397705</td>\n      <td>0.637141</td>\n      <td>0.234872</td>\n      <td>0.021379</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>534</th>\n      <td>403.0</td>\n      <td>1.237413</td>\n      <td>0.512365</td>\n      <td>0.687746</td>\n      <td>1.693872</td>\n      <td>-0.236323</td>\n      <td>-0.650232</td>\n      <td>0.118066</td>\n      <td>-0.230545</td>\n      <td>-0.808523</td>\n      <td>...</td>\n      <td>-0.077543</td>\n      <td>-0.178220</td>\n      <td>0.038722</td>\n      <td>0.471218</td>\n      <td>0.289249</td>\n      <td>0.871803</td>\n      <td>-0.066884</td>\n      <td>0.012986</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>541</th>\n      <td>406.0</td>\n      <td>-2.312227</td>\n      <td>1.951992</td>\n      <td>-1.609851</td>\n      <td>3.997906</td>\n      <td>-0.522188</td>\n      <td>-1.426545</td>\n      <td>-2.537387</td>\n      <td>1.391657</td>\n      <td>-2.770089</td>\n      <td>...</td>\n      <td>0.517232</td>\n      <td>-0.035049</td>\n      <td>-0.465211</td>\n      <td>0.320198</td>\n      <td>0.044519</td>\n      <td>0.177840</td>\n      <td>0.261145</td>\n      <td>-0.143276</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>575</th>\n      <td>430.0</td>\n      <td>-1.860258</td>\n      <td>-0.629859</td>\n      <td>0.966570</td>\n      <td>0.844632</td>\n      <td>0.759983</td>\n      <td>-1.481173</td>\n      <td>-0.509681</td>\n      <td>0.540722</td>\n      <td>-0.733623</td>\n      <td>...</td>\n      <td>0.268028</td>\n      <td>0.125515</td>\n      <td>-0.225029</td>\n      <td>0.586664</td>\n      <td>-0.031598</td>\n      <td>0.570168</td>\n      <td>-0.043007</td>\n      <td>-0.223739</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>283719</th>\n      <td>171817.0</td>\n      <td>-0.750414</td>\n      <td>0.904175</td>\n      <td>0.996461</td>\n      <td>0.427284</td>\n      <td>1.720336</td>\n      <td>0.929256</td>\n      <td>0.794272</td>\n      <td>0.176719</td>\n      <td>-1.836261</td>\n      <td>...</td>\n      <td>0.050750</td>\n      <td>0.115532</td>\n      <td>-0.623995</td>\n      <td>-0.186896</td>\n      <td>0.733759</td>\n      <td>2.558151</td>\n      <td>-0.188835</td>\n      <td>0.001654</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>283782</th>\n      <td>171870.0</td>\n      <td>2.083677</td>\n      <td>-0.065811</td>\n      <td>-1.442870</td>\n      <td>0.135416</td>\n      <td>0.043035</td>\n      <td>-1.306975</td>\n      <td>0.335835</td>\n      <td>-0.371635</td>\n      <td>0.730560</td>\n      <td>...</td>\n      <td>-0.147536</td>\n      <td>-0.246599</td>\n      <td>0.194758</td>\n      <td>-0.082277</td>\n      <td>0.012887</td>\n      <td>-0.069278</td>\n      <td>-0.048995</td>\n      <td>-0.065482</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>283949</th>\n      <td>172027.0</td>\n      <td>2.132569</td>\n      <td>-0.057836</td>\n      <td>-1.724522</td>\n      <td>-0.030326</td>\n      <td>0.412146</td>\n      <td>-0.903088</td>\n      <td>0.345843</td>\n      <td>-0.348132</td>\n      <td>0.722638</td>\n      <td>...</td>\n      <td>-0.188739</td>\n      <td>-0.343876</td>\n      <td>0.105024</td>\n      <td>-0.763831</td>\n      <td>0.117381</td>\n      <td>-0.027682</td>\n      <td>-0.047514</td>\n      <td>-0.071700</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284085</th>\n      <td>172140.0</td>\n      <td>-2.210521</td>\n      <td>-1.039425</td>\n      <td>0.189704</td>\n      <td>-1.291932</td>\n      <td>3.742120</td>\n      <td>-1.665061</td>\n      <td>3.120388</td>\n      <td>-2.324089</td>\n      <td>0.364926</td>\n      <td>...</td>\n      <td>-0.286359</td>\n      <td>1.326003</td>\n      <td>-0.361764</td>\n      <td>-0.268117</td>\n      <td>1.051309</td>\n      <td>0.334629</td>\n      <td>-1.930149</td>\n      <td>-0.899888</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284770</th>\n      <td>172759.0</td>\n      <td>-0.822731</td>\n      <td>1.270140</td>\n      <td>-0.138566</td>\n      <td>0.479620</td>\n      <td>1.242101</td>\n      <td>0.795218</td>\n      <td>0.454284</td>\n      <td>0.556038</td>\n      <td>-1.550610</td>\n      <td>...</td>\n      <td>0.138766</td>\n      <td>0.450908</td>\n      <td>-0.192146</td>\n      <td>-0.196218</td>\n      <td>-0.261664</td>\n      <td>2.372675</td>\n      <td>-0.042743</td>\n      <td>0.109613</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1825 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:28:21.250132Z","iopub.execute_input":"2023-12-11T07:28:21.254440Z","iopub.status.idle":"2023-12-11T07:28:21.271152Z","shell.execute_reply.started":"2023-12-11T07:28:21.254393Z","shell.execute_reply":"2023-12-11T07:28:21.268787Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n       'Class'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"df.Class.value_counts().plot.bar()","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:28:21.272823Z","iopub.execute_input":"2023-12-11T07:28:21.273222Z","iopub.status.idle":"2023-12-11T07:28:21.565272Z","shell.execute_reply.started":"2023-12-11T07:28:21.273184Z","shell.execute_reply":"2023-12-11T07:28:21.564177Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<Axes: xlabel='Class'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"df.isnull().sum()/df.shape[0]*100","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:28:21.566780Z","iopub.execute_input":"2023-12-11T07:28:21.567157Z","iopub.status.idle":"2023-12-11T07:28:21.591024Z","shell.execute_reply.started":"2023-12-11T07:28:21.567125Z","shell.execute_reply":"2023-12-11T07:28:21.590043Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Time      0.0\nV1        0.0\nV2        0.0\nV3        0.0\nV4        0.0\nV5        0.0\nV6        0.0\nV7        0.0\nV8        0.0\nV9        0.0\nV10       0.0\nV11       0.0\nV12       0.0\nV13       0.0\nV14       0.0\nV15       0.0\nV16       0.0\nV17       0.0\nV18       0.0\nV19       0.0\nV20       0.0\nV21       0.0\nV22       0.0\nV23       0.0\nV24       0.0\nV25       0.0\nV26       0.0\nV27       0.0\nV28       0.0\nAmount    0.0\nClass     0.0\ndtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"df.nlargest(10,'Amount')","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:28:21.592627Z","iopub.execute_input":"2023-12-11T07:28:21.592992Z","iopub.status.idle":"2023-12-11T07:28:21.667094Z","shell.execute_reply.started":"2023-12-11T07:28:21.592963Z","shell.execute_reply":"2023-12-11T07:28:21.665984Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"            Time         V1         V2         V3         V4          V5  \\\n274771  166198.0 -35.548539 -31.850484 -48.325589  15.304184 -113.743307   \n58465    48401.0 -36.802320 -63.344698 -20.645794  16.715537  -20.672064   \n151296   95286.0 -34.549296 -60.464618 -21.340854  16.875344  -19.229075   \n46841    42951.0 -23.712839 -42.172688 -13.320825   9.925019  -13.945538   \n54018    46253.0 -21.780665 -38.305310 -12.122469   9.752791  -12.880794   \n169457  119713.0 -20.924897 -37.943452 -14.060281  10.473005  -10.866639   \n284249  172273.0  -9.030538 -11.112584 -16.233798   3.592021  -40.427726   \n227921  145283.0 -21.532478 -34.704768  -8.303035  10.264175    3.957175   \n74699    55709.0 -16.950064 -16.417395 -12.523381   6.555638  -27.752964   \n245474  152763.0 -14.641710 -28.554825 -12.714462   5.878264   -7.855074   \n\n               V6          V7         V8        V9  ...        V21        V22  \\\n274771  73.301626  120.589494 -27.347360 -3.872425  ... -21.620120   5.712303   \n58465    7.694002   24.956587  -4.730111 -2.687312  ...  11.455313 -10.933144   \n151296   6.335259   24.422716  -4.964566  0.188912  ...  11.502580  -9.499423   \n46841    5.564891   15.710644  -2.844253 -1.580725  ...   7.921600  -6.320710   \n54018    4.256017   14.785051  -2.818253 -0.667338  ...   7.437478  -5.619439   \n169457   6.256654   14.960521  -2.392155 -0.597076  ...   6.829810  -6.926353   \n284249  23.917837   44.054461  -7.277778 -4.210637  ...  -0.269048   0.988144   \n227921  -3.229695   -4.066768  -4.083971  0.554072  ...   5.198718  -7.331078   \n74699   18.072031   28.504065 -10.152220  2.124673  ...  -5.932594   0.050097   \n245474   2.471004   11.922577  -2.651203 -2.223985  ...   5.788207  -3.269671   \n\n              V23       V24       V25       V26        V27        V28  \\\n274771  -1.581098  4.584549  4.554683  3.415636  31.612198 -15.430084   \n58465  -17.173665  1.180700 -7.025783 -2.534330  -3.602479   3.450224   \n151296 -16.513186  0.744341 -7.081325 -2.604551  -3.550963   3.250802   \n46841  -11.310338  0.404175 -4.547278 -1.577118  -2.357385   2.253662   \n54018  -10.547038  0.653249 -4.232409 -0.480459  -2.257913   2.082488   \n169457  -9.928657 -0.447084 -4.848151 -2.241620  -2.140723   2.001492   \n284249   7.040028  0.347693  2.520869  2.342495   3.478175  -2.713136   \n227921 -32.828995  0.118986 -8.696627 -1.778061  -0.519786   2.716716   \n74699  -10.855949  1.550407 -0.502172  0.821714  12.152401  -4.009839   \n245474  -8.024556  0.423021 -2.396701 -0.633380  -1.763704   1.422017   \n\n          Amount  Class  \n274771  25691.16      0  \n58465   19656.53      0  \n151296  18910.00      0  \n46841   12910.93      0  \n54018   11898.09      0  \n169457  11789.84      0  \n284249  10199.44      0  \n227921  10000.00      0  \n74699    8790.26      0  \n245474   8787.00      0  \n\n[10 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>274771</th>\n      <td>166198.0</td>\n      <td>-35.548539</td>\n      <td>-31.850484</td>\n      <td>-48.325589</td>\n      <td>15.304184</td>\n      <td>-113.743307</td>\n      <td>73.301626</td>\n      <td>120.589494</td>\n      <td>-27.347360</td>\n      <td>-3.872425</td>\n      <td>...</td>\n      <td>-21.620120</td>\n      <td>5.712303</td>\n      <td>-1.581098</td>\n      <td>4.584549</td>\n      <td>4.554683</td>\n      <td>3.415636</td>\n      <td>31.612198</td>\n      <td>-15.430084</td>\n      <td>25691.16</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>58465</th>\n      <td>48401.0</td>\n      <td>-36.802320</td>\n      <td>-63.344698</td>\n      <td>-20.645794</td>\n      <td>16.715537</td>\n      <td>-20.672064</td>\n      <td>7.694002</td>\n      <td>24.956587</td>\n      <td>-4.730111</td>\n      <td>-2.687312</td>\n      <td>...</td>\n      <td>11.455313</td>\n      <td>-10.933144</td>\n      <td>-17.173665</td>\n      <td>1.180700</td>\n      <td>-7.025783</td>\n      <td>-2.534330</td>\n      <td>-3.602479</td>\n      <td>3.450224</td>\n      <td>19656.53</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>151296</th>\n      <td>95286.0</td>\n      <td>-34.549296</td>\n      <td>-60.464618</td>\n      <td>-21.340854</td>\n      <td>16.875344</td>\n      <td>-19.229075</td>\n      <td>6.335259</td>\n      <td>24.422716</td>\n      <td>-4.964566</td>\n      <td>0.188912</td>\n      <td>...</td>\n      <td>11.502580</td>\n      <td>-9.499423</td>\n      <td>-16.513186</td>\n      <td>0.744341</td>\n      <td>-7.081325</td>\n      <td>-2.604551</td>\n      <td>-3.550963</td>\n      <td>3.250802</td>\n      <td>18910.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>46841</th>\n      <td>42951.0</td>\n      <td>-23.712839</td>\n      <td>-42.172688</td>\n      <td>-13.320825</td>\n      <td>9.925019</td>\n      <td>-13.945538</td>\n      <td>5.564891</td>\n      <td>15.710644</td>\n      <td>-2.844253</td>\n      <td>-1.580725</td>\n      <td>...</td>\n      <td>7.921600</td>\n      <td>-6.320710</td>\n      <td>-11.310338</td>\n      <td>0.404175</td>\n      <td>-4.547278</td>\n      <td>-1.577118</td>\n      <td>-2.357385</td>\n      <td>2.253662</td>\n      <td>12910.93</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>54018</th>\n      <td>46253.0</td>\n      <td>-21.780665</td>\n      <td>-38.305310</td>\n      <td>-12.122469</td>\n      <td>9.752791</td>\n      <td>-12.880794</td>\n      <td>4.256017</td>\n      <td>14.785051</td>\n      <td>-2.818253</td>\n      <td>-0.667338</td>\n      <td>...</td>\n      <td>7.437478</td>\n      <td>-5.619439</td>\n      <td>-10.547038</td>\n      <td>0.653249</td>\n      <td>-4.232409</td>\n      <td>-0.480459</td>\n      <td>-2.257913</td>\n      <td>2.082488</td>\n      <td>11898.09</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>169457</th>\n      <td>119713.0</td>\n      <td>-20.924897</td>\n      <td>-37.943452</td>\n      <td>-14.060281</td>\n      <td>10.473005</td>\n      <td>-10.866639</td>\n      <td>6.256654</td>\n      <td>14.960521</td>\n      <td>-2.392155</td>\n      <td>-0.597076</td>\n      <td>...</td>\n      <td>6.829810</td>\n      <td>-6.926353</td>\n      <td>-9.928657</td>\n      <td>-0.447084</td>\n      <td>-4.848151</td>\n      <td>-2.241620</td>\n      <td>-2.140723</td>\n      <td>2.001492</td>\n      <td>11789.84</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284249</th>\n      <td>172273.0</td>\n      <td>-9.030538</td>\n      <td>-11.112584</td>\n      <td>-16.233798</td>\n      <td>3.592021</td>\n      <td>-40.427726</td>\n      <td>23.917837</td>\n      <td>44.054461</td>\n      <td>-7.277778</td>\n      <td>-4.210637</td>\n      <td>...</td>\n      <td>-0.269048</td>\n      <td>0.988144</td>\n      <td>7.040028</td>\n      <td>0.347693</td>\n      <td>2.520869</td>\n      <td>2.342495</td>\n      <td>3.478175</td>\n      <td>-2.713136</td>\n      <td>10199.44</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>227921</th>\n      <td>145283.0</td>\n      <td>-21.532478</td>\n      <td>-34.704768</td>\n      <td>-8.303035</td>\n      <td>10.264175</td>\n      <td>3.957175</td>\n      <td>-3.229695</td>\n      <td>-4.066768</td>\n      <td>-4.083971</td>\n      <td>0.554072</td>\n      <td>...</td>\n      <td>5.198718</td>\n      <td>-7.331078</td>\n      <td>-32.828995</td>\n      <td>0.118986</td>\n      <td>-8.696627</td>\n      <td>-1.778061</td>\n      <td>-0.519786</td>\n      <td>2.716716</td>\n      <td>10000.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>74699</th>\n      <td>55709.0</td>\n      <td>-16.950064</td>\n      <td>-16.417395</td>\n      <td>-12.523381</td>\n      <td>6.555638</td>\n      <td>-27.752964</td>\n      <td>18.072031</td>\n      <td>28.504065</td>\n      <td>-10.152220</td>\n      <td>2.124673</td>\n      <td>...</td>\n      <td>-5.932594</td>\n      <td>0.050097</td>\n      <td>-10.855949</td>\n      <td>1.550407</td>\n      <td>-0.502172</td>\n      <td>0.821714</td>\n      <td>12.152401</td>\n      <td>-4.009839</td>\n      <td>8790.26</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>245474</th>\n      <td>152763.0</td>\n      <td>-14.641710</td>\n      <td>-28.554825</td>\n      <td>-12.714462</td>\n      <td>5.878264</td>\n      <td>-7.855074</td>\n      <td>2.471004</td>\n      <td>11.922577</td>\n      <td>-2.651203</td>\n      <td>-2.223985</td>\n      <td>...</td>\n      <td>5.788207</td>\n      <td>-3.269671</td>\n      <td>-8.024556</td>\n      <td>0.423021</td>\n      <td>-2.396701</td>\n      <td>-0.633380</td>\n      <td>-1.763704</td>\n      <td>1.422017</td>\n      <td>8787.00</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.drop_duplicates(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:28:21.673340Z","iopub.execute_input":"2023-12-11T07:28:21.673855Z","iopub.status.idle":"2023-12-11T07:28:22.699994Z","shell.execute_reply.started":"2023-12-11T07:28:21.673811Z","shell.execute_reply":"2023-12-11T07:28:22.698998Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:28:22.701219Z","iopub.execute_input":"2023-12-11T07:28:22.701536Z","iopub.status.idle":"2023-12-11T07:28:22.707655Z","shell.execute_reply.started":"2023-12-11T07:28:22.701507Z","shell.execute_reply":"2023-12-11T07:28:22.706887Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(283726, 31)"},"metadata":{}}]},{"cell_type":"code","source":"print(df.Amount.mean())\nprint(df.Amount.mode())\nprint(df.Amount.median())","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:28:22.709018Z","iopub.execute_input":"2023-12-11T07:28:22.709562Z","iopub.status.idle":"2023-12-11T07:28:22.737739Z","shell.execute_reply.started":"2023-12-11T07:28:22.709532Z","shell.execute_reply":"2023-12-11T07:28:22.736549Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"88.47268731099724\n0    1.0\nName: Amount, dtype: float64\n22.0\n","output_type":"stream"}]},{"cell_type":"code","source":"df.Class.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:28:22.739162Z","iopub.execute_input":"2023-12-11T07:28:22.740277Z","iopub.status.idle":"2023-12-11T07:28:22.751457Z","shell.execute_reply.started":"2023-12-11T07:28:22.740232Z","shell.execute_reply":"2023-12-11T07:28:22.750304Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Class\n0    283253\n1       473\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"x=df.drop(['Class'],axis=1)\ny=df.Class","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:28:22.753226Z","iopub.execute_input":"2023-12-11T07:28:22.753613Z","iopub.status.idle":"2023-12-11T07:28:22.793272Z","shell.execute_reply.started":"2023-12-11T07:28:22.753566Z","shell.execute_reply":"2023-12-11T07:28:22.791505Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nsm=SMOTE(random_state=50)\nxres,yres = sm.fit_resample(x,y)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:28:22.795237Z","iopub.execute_input":"2023-12-11T07:28:22.797432Z","iopub.status.idle":"2023-12-11T07:28:23.892786Z","shell.execute_reply.started":"2023-12-11T07:28:22.797380Z","shell.execute_reply":"2023-12-11T07:28:23.891806Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"yres.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:28:23.894493Z","iopub.execute_input":"2023-12-11T07:28:23.895398Z","iopub.status.idle":"2023-12-11T07:28:23.909301Z","shell.execute_reply.started":"2023-12-11T07:28:23.895357Z","shell.execute_reply":"2023-12-11T07:28:23.908474Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"Class\n0    283253\n1    283253\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"xres.size","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:28:23.910378Z","iopub.execute_input":"2023-12-11T07:28:23.911182Z","iopub.status.idle":"2023-12-11T07:28:23.921501Z","shell.execute_reply.started":"2023-12-11T07:28:23.911148Z","shell.execute_reply":"2023-12-11T07:28:23.920372Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"16995180"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\nscaler.fit(xres)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:28:23.923484Z","iopub.execute_input":"2023-12-11T07:28:23.924455Z","iopub.status.idle":"2023-12-11T07:28:24.022067Z","shell.execute_reply.started":"2023-12-11T07:28:23.924418Z","shell.execute_reply":"2023-12-11T07:28:24.020918Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"MinMaxScaler()","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"x=scaler.transform(xres)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:28:24.023806Z","iopub.execute_input":"2023-12-11T07:28:24.024263Z","iopub.status.idle":"2023-12-11T07:28:24.169706Z","shell.execute_reply.started":"2023-12-11T07:28:24.024211Z","shell.execute_reply":"2023-12-11T07:28:24.168537Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,yres,train_size=0.70,random_state=42)\nx_train","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:28:24.171040Z","iopub.execute_input":"2023-12-11T07:28:24.171597Z","iopub.status.idle":"2023-12-11T07:28:24.451069Z","shell.execute_reply.started":"2023-12-11T07:28:24.171563Z","shell.execute_reply":"2023-12-11T07:28:24.449919Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"array([[7.06849854e-01, 9.83023779e-01, 7.48668869e-01, ...,\n        4.15493397e-01, 3.13093276e-01, 1.36677363e-02],\n       [5.07882309e-01, 9.92182917e-01, 7.65151169e-01, ...,\n        4.17301885e-01, 3.12674869e-01, 1.94230233e-04],\n       [3.00714153e-01, 9.79552308e-01, 7.65529551e-01, ...,\n        4.16305355e-01, 3.12815730e-01, 3.88849706e-04],\n       ...,\n       [3.43766088e-01, 8.35872104e-01, 6.98260972e-01, ...,\n        4.31436477e-01, 2.93150025e-01, 7.12593756e-04],\n       [4.62886013e-01, 9.79687898e-01, 7.66736240e-01, ...,\n        4.17358779e-01, 3.13632692e-01, 1.75157525e-04],\n       [4.43064494e-01, 9.50391451e-01, 7.75894049e-01, ...,\n        4.14095342e-01, 3.12157074e-01, 0.00000000e+00]])"},"metadata":{}}]},{"cell_type":"markdown","source":"Logistic Regression","metadata":{}},{"cell_type":"code","source":"#hyperparameter tuning\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nlr=LogisticRegression()\nparam_grid={\n    'penalty':['l1','l2'],\n    'max_iter':[50,100,200]\n}\ngcv=GridSearchCV(lr,param_grid,scoring='balanced_accuracy',cv=5)\ngcv.fit(x_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:28:24.452242Z","iopub.execute_input":"2023-12-11T07:28:24.452547Z","iopub.status.idle":"2023-12-11T07:30:17.922617Z","shell.execute_reply.started":"2023-12-11T07:28:24.452520Z","shell.execute_reply":"2023-12-11T07:30:17.921525Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n15 fits failed out of a total of 30.\nThe score on these train-test partitions for these parameters will be set to nan.\nIf these failures are not expected, you can try to debug them by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n15 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n    solver = _check_solver(self.solver, self.penalty, self.dual)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n    raise ValueError(\nValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n\n  warnings.warn(some_fits_failed_message, FitFailedWarning)\n/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.97303191        nan 0.97381644        nan 0.97444215]\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(cv=5, estimator=LogisticRegression(),\n             param_grid={'max_iter': [50, 100, 200], 'penalty': ['l1', 'l2']},\n             scoring='balanced_accuracy')","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n             param_grid={&#x27;max_iter&#x27;: [50, 100, 200], &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]},\n             scoring=&#x27;balanced_accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n             param_grid={&#x27;max_iter&#x27;: [50, 100, 200], &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]},\n             scoring=&#x27;balanced_accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"gcv.best_params_","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:30:17.924385Z","iopub.execute_input":"2023-12-11T07:30:17.933887Z","iopub.status.idle":"2023-12-11T07:30:17.949175Z","shell.execute_reply.started":"2023-12-11T07:30:17.933808Z","shell.execute_reply":"2023-12-11T07:30:17.947597Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"{'max_iter': 200, 'penalty': 'l2'}"},"metadata":{}}]},{"cell_type":"code","source":"gcv.best_score_","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:30:17.952056Z","iopub.execute_input":"2023-12-11T07:30:17.953252Z","iopub.status.idle":"2023-12-11T07:30:17.972738Z","shell.execute_reply.started":"2023-12-11T07:30:17.953186Z","shell.execute_reply":"2023-12-11T07:30:17.971258Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"0.974442148211299"},"metadata":{}}]},{"cell_type":"code","source":"lr=LogisticRegression(penalty='l2',max_iter=200)\nlr.fit(x_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:32:05.672784Z","iopub.execute_input":"2023-12-11T07:32:05.673171Z","iopub.status.idle":"2023-12-11T07:32:20.209881Z","shell.execute_reply.started":"2023-12-11T07:32:05.673141Z","shell.execute_reply":"2023-12-11T07:32:20.208393Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"LogisticRegression(max_iter=200)","text/html":"<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=200)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"y_pred=lr.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:32:37.111491Z","iopub.execute_input":"2023-12-11T07:32:37.111933Z","iopub.status.idle":"2023-12-11T07:32:37.129056Z","shell.execute_reply.started":"2023-12-11T07:32:37.111896Z","shell.execute_reply":"2023-12-11T07:32:37.127330Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_pred,y_test))","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:32:39.283293Z","iopub.execute_input":"2023-12-11T07:32:39.283734Z","iopub.status.idle":"2023-12-11T07:32:39.622390Z","shell.execute_reply.started":"2023-12-11T07:32:39.283697Z","shell.execute_reply":"2023-12-11T07:32:39.621157Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.99      0.96      0.98     87426\n           1       0.96      0.99      0.98     82526\n\n    accuracy                           0.98    169952\n   macro avg       0.98      0.98      0.98    169952\nweighted avg       0.98      0.98      0.98    169952\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn=KNeighborsClassifier()\nknn.fit(x_train,y_train)\ny_pred=knn.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:32:59.394355Z","iopub.execute_input":"2023-12-11T07:32:59.394813Z","iopub.status.idle":"2023-12-11T07:36:17.674087Z","shell.execute_reply.started":"2023-12-11T07:32:59.394768Z","shell.execute_reply":"2023-12-11T07:36:17.672954Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_pred,y_test))","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:36:41.854811Z","iopub.execute_input":"2023-12-11T07:36:41.855206Z","iopub.status.idle":"2023-12-11T07:36:42.192473Z","shell.execute_reply.started":"2023-12-11T07:36:41.855176Z","shell.execute_reply":"2023-12-11T07:36:42.191187Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     84763\n           1       1.00      1.00      1.00     85189\n\n    accuracy                           1.00    169952\n   macro avg       1.00      1.00      1.00    169952\nweighted avg       1.00      1.00      1.00    169952\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.naive_bayes import ComplementNB\ncnb=ComplementNB()\ncnb.fit(x_train,y_train)\ny_pred=cnb.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:37:03.859836Z","iopub.execute_input":"2023-12-11T07:37:03.860217Z","iopub.status.idle":"2023-12-11T07:37:04.001352Z","shell.execute_reply.started":"2023-12-11T07:37:03.860176Z","shell.execute_reply":"2023-12-11T07:37:03.999742Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_pred,y_test))","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:37:07.261670Z","iopub.execute_input":"2023-12-11T07:37:07.262080Z","iopub.status.idle":"2023-12-11T07:37:07.596480Z","shell.execute_reply.started":"2023-12-11T07:37:07.262046Z","shell.execute_reply":"2023-12-11T07:37:07.595397Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       1.00      0.81      0.89    104782\n           1       0.77      1.00      0.87     65170\n\n    accuracy                           0.88    169952\n   macro avg       0.88      0.90      0.88    169952\nweighted avg       0.91      0.88      0.88    169952\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndt=DecisionTreeClassifier()\ndt.fit(x_train,y_train)\ny_pred=dt.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:37:13.848742Z","iopub.execute_input":"2023-12-11T07:37:13.849172Z","iopub.status.idle":"2023-12-11T07:38:09.475188Z","shell.execute_reply.started":"2023-12-11T07:37:13.849137Z","shell.execute_reply":"2023-12-11T07:38:09.474175Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_pred,y_test))","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:38:33.102594Z","iopub.execute_input":"2023-12-11T07:38:33.103036Z","iopub.status.idle":"2023-12-11T07:38:33.436059Z","shell.execute_reply.started":"2023-12-11T07:38:33.103001Z","shell.execute_reply":"2023-12-11T07:38:33.434767Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     84758\n           1       1.00      1.00      1.00     85194\n\n    accuracy                           1.00    169952\n   macro avg       1.00      1.00      1.00    169952\nweighted avg       1.00      1.00      1.00    169952\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf=RandomForestClassifier()\nrf.fit(x_train,y_train)\nypred=rf.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:40:52.539287Z","iopub.execute_input":"2023-12-11T07:40:52.539733Z","iopub.status.idle":"2023-12-11T07:49:06.576589Z","shell.execute_reply.started":"2023-12-11T07:40:52.539694Z","shell.execute_reply":"2023-12-11T07:49:06.575665Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_pred,y_test))","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:49:34.987947Z","iopub.execute_input":"2023-12-11T07:49:34.988338Z","iopub.status.idle":"2023-12-11T07:49:35.326357Z","shell.execute_reply.started":"2023-12-11T07:49:34.988299Z","shell.execute_reply":"2023-12-11T07:49:35.325275Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     84758\n           1       1.00      1.00      1.00     85194\n\n    accuracy                           1.00    169952\n   macro avg       1.00      1.00      1.00    169952\nweighted avg       1.00      1.00      1.00    169952\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\nxgb=XGBClassifier()\nparams={'eta':[0.1,0.2,0.3],\n       'max_depth':[3,4,5,6],\n       'lambda':[1,2]}\ngcv=GridSearchCV(xg,param_grid=params,cv=5,scoring='accuracy')\ngcv.fit(x_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:57:54.764313Z","iopub.execute_input":"2023-12-11T07:57:54.764767Z","iopub.status.idle":"2023-12-11T08:06:37.694464Z","shell.execute_reply.started":"2023-12-11T07:57:54.764720Z","shell.execute_reply":"2023-12-11T08:06:37.693576Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(cv=5,\n             estimator=XGBClassifier(base_score=None, booster=None,\n                                     callbacks=None, colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None, device=None,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False, eval_metric=None,\n                                     feature_types=None, gamma=None,\n                                     grow_policy=None, importance_type=None,\n                                     interaction_constraints=None,\n                                     learning_rate=None,...in=None,\n                                     max_cat_threshold=None,\n                                     max_cat_to_onehot=None,\n                                     max_delta_step=None, max_depth=None,\n                                     max_leaves=None, min_child_weight=None,\n                                     missing=nan, monotone_constraints=None,\n                                     multi_strategy=None, n_estimators=None,\n                                     n_jobs=None, num_parallel_tree=None,\n                                     random_state=None, ...),\n             param_grid={'eta': [0.1, 0.2, 0.3], 'lambda': [1, 2],\n                         'max_depth': [3, 4, 5, 6]},\n             scoring='accuracy')","text/html":"<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n             estimator=XGBClassifier(base_score=None, booster=None,\n                                     callbacks=None, colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None, device=None,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False, eval_metric=None,\n                                     feature_types=None, gamma=None,\n                                     grow_policy=None, importance_type=None,\n                                     interaction_constraints=None,\n                                     learning_rate=None,...in=None,\n                                     max_cat_threshold=None,\n                                     max_cat_to_onehot=None,\n                                     max_delta_step=None, max_depth=None,\n                                     max_leaves=None, min_child_weight=None,\n                                     missing=nan, monotone_constraints=None,\n                                     multi_strategy=None, n_estimators=None,\n                                     n_jobs=None, num_parallel_tree=None,\n                                     random_state=None, ...),\n             param_grid={&#x27;eta&#x27;: [0.1, 0.2, 0.3], &#x27;lambda&#x27;: [1, 2],\n                         &#x27;max_depth&#x27;: [3, 4, 5, 6]},\n             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n             estimator=XGBClassifier(base_score=None, booster=None,\n                                     callbacks=None, colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None, device=None,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False, eval_metric=None,\n                                     feature_types=None, gamma=None,\n                                     grow_policy=None, importance_type=None,\n                                     interaction_constraints=None,\n                                     learning_rate=None,...in=None,\n                                     max_cat_threshold=None,\n                                     max_cat_to_onehot=None,\n                                     max_delta_step=None, max_depth=None,\n                                     max_leaves=None, min_child_weight=None,\n                                     missing=nan, monotone_constraints=None,\n                                     multi_strategy=None, n_estimators=None,\n                                     n_jobs=None, num_parallel_tree=None,\n                                     random_state=None, ...),\n             param_grid={&#x27;eta&#x27;: [0.1, 0.2, 0.3], &#x27;lambda&#x27;: [1, 2],\n                         &#x27;max_depth&#x27;: [3, 4, 5, 6]},\n             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"gcv.best_params_","metadata":{"execution":{"iopub.status.busy":"2023-12-11T08:07:08.345766Z","iopub.execute_input":"2023-12-11T08:07:08.346196Z","iopub.status.idle":"2023-12-11T08:07:08.353477Z","shell.execute_reply.started":"2023-12-11T08:07:08.346158Z","shell.execute_reply":"2023-12-11T08:07:08.352472Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"{'eta': 0.3, 'lambda': 2, 'max_depth': 6}"},"metadata":{}}]},{"cell_type":"code","source":"xg=XGBClassifier(eta=0.3,max_depth=6)\nxg.fit(x_train,y_train)\ny_pred=xg.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T08:08:20.504816Z","iopub.execute_input":"2023-12-11T08:08:20.505250Z","iopub.status.idle":"2023-12-11T08:08:26.580851Z","shell.execute_reply.started":"2023-12-11T08:08:20.505216Z","shell.execute_reply":"2023-12-11T08:08:26.579454Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_pred,y_test))","metadata":{"execution":{"iopub.status.busy":"2023-12-11T08:08:32.099025Z","iopub.execute_input":"2023-12-11T08:08:32.099456Z","iopub.status.idle":"2023-12-11T08:08:32.440584Z","shell.execute_reply.started":"2023-12-11T08:08:32.099423Z","shell.execute_reply":"2023-12-11T08:08:32.438976Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     84849\n           1       1.00      1.00      1.00     85103\n\n    accuracy                           1.00    169952\n   macro avg       1.00      1.00      1.00    169952\nweighted avg       1.00      1.00      1.00    169952\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}